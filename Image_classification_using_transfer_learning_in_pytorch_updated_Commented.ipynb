{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty-nSgy2Bai0"
      },
      "source": [
        "<h1 style=\"font-size:30px;\">Image Classification Using Transfer Learning with Torchvision</h1>  \n",
        "  \n",
        "\n",
        "\n",
        "In this notebook, we will learn how to train an Image Classifier on the **Caltech-256** dataset subset provided by using a pretrained model. We will use the **ResNet-50** network architecture but we instantiate the convolutional base of the network with weights that have been pre-trained on the ImageNet dataset.\n",
        "\n",
        "We will add our own classification layer and only train the classifier part of the network. This technique is called transfer learning.\n",
        "\n",
        "Finally we  will demonstrate that using a pre-trained convolutional base results in a tremendous jump in the performance metrics with literally no effort.\n",
        "\n",
        "------------------------------------- **Caltech-256 Dataset** -----------------------------------------\n",
        "\n",
        "\n",
        "<img src=https://production-media.paperswithcode.com/datasets/CALTECH.jpg width=500 height=400 align='center'><br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUJOHSpfCsyX"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [1. Overview of Pre-Trained Model Use Cases](#1.-Overview-of-Pre-Trained-Model-Use-Cases)\n",
        "* [2. Download and Extract the Caltech256 Subset Dataset](#2.-Download-and-Extract-the-Caltech256-Subset-Dataset)\n",
        "* [3. DataLoader Preparation](#3.-DataLoader-Preparation)\n",
        "* [4. Load the ResNet50 Pre-Trained Model](#4.-Load-the-ResNet50-Pre-Trained-Model)\n",
        "* [5. Model Training](#5.-Model-Training)\n",
        "* [6. Inference](#6.-Inference)\n",
        "* [7. Conclusion](#7.-Conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iFezG6WJBO"
      },
      "source": [
        "## 1. Overview of Pre-Trained Model Use Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcxv2Hz8L7H6"
      },
      "source": [
        "A typical image classification architecture consists of 4 parts\n",
        "\n",
        "\n",
        "1.   Input image\n",
        "2.   Feature Extractor - a bank of convolutional layers that extract useful features for classification.\n",
        "3.   Classifier - a bank of fully connected layers that classify the image into its output classes.  \n",
        "4.   Output vector of class probabilities\n",
        "\n",
        "\n",
        "<img src=https://learnopencv.com/wp-content/uploads/2024/07/Transfer-learning.png align='center'><br/>\n",
        "\n",
        "Before we proceed with the coding implementation for Transfer Learning, it's helpful to review the table below, which summarizes several use cases.\n",
        "\n",
        "<img src=https://learnopencv.com/wp-content/uploads/2023/03/tensorflow-keras-training-methods.png width=850 align='center'><br/>\n",
        "\n",
        "\n",
        "\n",
        "### 1.1. Pre-Trained ImageNet Models\n",
        "\n",
        "If you have a need to perform image classification on a wide range of content that encompasses many of the classes in ImageNet, then using a pre-trained model is an excellent choice. As the name implies, no training is required; you can simply load the model and make predictions on your pre-processed input images. There are many pre-trained models available in Torchvision, which you can select from. See our previous post on this topic for more details.\n",
        "\n",
        "For situations where your application contains specific classes that are not contained in ImageNet we can perform finetuning by unfreezing several conv layers to adapt to new features.\n",
        "\n",
        "In a previous notebook, we showed how you can use pre-trained ImageNet models to perform classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz7tKEOjMaVO"
      },
      "source": [
        "### 1.2. Train from Scratch\n",
        "\n",
        "If you need to customize a model for a new dataset, one option is to load a model and train it from scratch. When training from scratch, the entire model is initialized with random weights, and training is performed from scratch (with the redefined classifier).\n",
        "\n",
        " Training a model from scratch requires a lot of data and a lot of computational resources, although this depends on the size of the model. Still, it's a significant factor to consider, especially if you don't have much data and acquiring labeled training data for your application is difficult. Better options exist, but for reference, we trained the dustom model from scratch in one of our previous post trained on 10 Monkey Species Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arhyD2fzMjKU"
      },
      "source": [
        "### 1.3. Transfer Learning\n",
        "\n",
        "Transfer Learning is a simple approach for re-purposing a pre-trained model to make predictions on a new dataset. The concept is simple. We use the model's pre-trained feature extractor (convolutional base) and re-train a new classifier to learn new weights for the new dataset. This is sometimes referred to as \"freezing\" the layers in the feature extractor, meaning that we load the pre-trained weights and do not attempt to modify them further during the training process. The theory is that the pre-trained ImageNet Feature Extractor has learned valuable features for detecting many different object types. We assume such features are general enough that we only need to re-train the classifier portion of the network.\n",
        "\n",
        "This approach requires much less data and computational resources than training from scratch. Remember that training a model often takes many iterations to determine an appropriate set of hyper-parameters for a final model, so the time required to experiment and iterate will be significantly compounded. Since pre-trained models were trained on millions of images, it behooves us to try and leverage that inherent capability. Transfer learning allows you to quickly study how a pre-trained model can be customized for a new dataset. However, sometimes retraining the classifier isn't enough. This is where Fine-Tuning can be very beneficial.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0yIqEIjNRmx"
      },
      "source": [
        "### 1.4. Fine Tuning\n",
        "\n",
        "Fine-Tuning represents a flexible alternative to Transfer Learning. It is very similar to Transfer Learning. Instead of locking down the feature extractor completely, we load the feature extractor with ImageNet weights and then freeze the first several layers of the feature extractor but allow the last few layers to be trained further. The idea is that the first several layers in the feature extractor represent generic, low-level features (e.g., edges, corners, and arcs) that are fundamental building blocks necessary to support many classification tasks. Subsequent layers in the feature extractor build upon the lower-level features to learn more complex representations that are more closely related to the content of a particular dataset.\n",
        "\n",
        "\n",
        "With Fine-Tuning, we can specifically leverage the lower-level features of the pre-trained model but provide some flexibility for \"fine-tuning\" the last few layers of the convolutional base to provide the best possible customization for the dataset. So we \"freeze\" the initial layers (i.e., make them non-trainable) and let the model train the last few layers of the feature extractor, as well as the classifier. Note that all the layers in the feature extractor are initialized to ImageNet weights. Once training begins, the weights in the last few layers of the feature extractor are updated further, which is why this approach is called Fine-Tuning. Also, the weights in the classifier are initialized to small random values since we want the classifier to learn new weights required to classify new content.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM6CkjqzCn4k"
      },
      "source": [
        "### Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEwtGG2jqFrJ"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrL47MttOLS3"
      },
      "outputs": [],
      "source": [
        "import torch  # Import PyTorch for deep learning computations\n",
        "import torchvision  # Import torchvision for pre-trained models and datasets\n",
        "import torch.nn as nn  # Import neural network module from PyTorch\n",
        "import torch.optim as optim  # Import optimizers for training models\n",
        "import time  # Import time module for measuring execution time\n",
        "import numpy as np  # Import NumPy for numerical operations\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib for visualization\n",
        "import os  # Import os for file system operations\n",
        "import zipfile  # Import zipfile for extracting compressed datasets\n",
        "import requests  # Import requests for downloading files\n",
        "\n",
        "import pandas as pd  # Import pandas for data manipulation and analysis\n",
        "from PIL import Image  # Import PIL for image processing\n",
        "from torchvision import datasets, models, transforms  # Import datasets, pre-trained models, and transformations from torchvision\n",
        "from torchinfo import summary  # Import torchinfo for displaying model summaries\n",
        "from torch.utils.data import DataLoader  # Import DataLoader for handling batch data loading\n",
        "\n",
        "plt.style.use('ggplot')  # Set the Matplotlib style to 'ggplot' for better visuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc-dcgIVCyQi"
      },
      "source": [
        "## 2. Download and Extract the Caltech256 Subset Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WMfk1fwo18r"
      },
      "outputs": [],
      "source": [
        "# Helper function to download file.\n",
        "def download_file(url, save_name):\n",
        "    url = url\n",
        "    if not os.path.exists(save_name):\n",
        "        file = requests.get(url)\n",
        "        open(save_name, 'wb').write(file.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AZsspixo18s"
      },
      "outputs": [],
      "source": [
        "# Download the dataset.\n",
        "download_file(\n",
        "    'https://www.dropbox.com/s/0ltu2bsja3sb2j4/caltech256_subset.zip?dl=1',\n",
        "    'caltech256_subset.zip'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEpJq93no18t",
        "outputId": "6ffed212-2c40-45ee-c3e5-54846365bcbb"
      },
      "outputs": [],
      "source": [
        "# Extract the dataset.\n",
        "file = 'caltech256_subset.zip'\n",
        "with zipfile.ZipFile(file, 'r') as zip:\n",
        "    # extract all files\n",
        "    print('extraction...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJsjmdkMEXqz"
      },
      "source": [
        "## 3. DataLoader Preparation\n",
        "\n",
        "The dataset we will be using here is a subset of Caltech256 dataset\n",
        " containing 10 categories and number of samples as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfefU2pxPVA3"
      },
      "source": [
        "|     Class     | Train Samples | Valid Samples | Test Samples |\n",
        "|:-------------:|:-------------:|:-------------:|:------------:|\n",
        "|      bear     |       60      |       10      |      10      |\n",
        "|     chimp     |       60      |       10      |      10      |\n",
        "|    giraffe    |       60      |       10      |      10      |\n",
        "|    gorilla    |       60      |       10      |      10      |\n",
        "|     llama     |       60      |       10      |      10      |\n",
        "|    ostrich    |       60      |       10      |      10      |\n",
        "|   porcupine   |       60      |       10      |      10      |\n",
        "|     skunk     |       60      |       10      |      10      |\n",
        "| triceratops   |       60      |       10      |      10      |\n",
        "|     zebra     |       60      |       10      |      10      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTiZYqqrEdic"
      },
      "source": [
        "### 3.1. Preprocessing Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Jwg9JJOLTE"
      },
      "outputs": [],
      "source": [
        "# Defining transformations to be applied to training, validation, and test datasets\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),  # Randomly crop the image with scaling\n",
        "        transforms.RandomRotation(degrees=15),  # Apply random rotation up to 15 degrees\n",
        "        transforms.RandomHorizontalFlip(),  # Flip the image horizontally with a probability of 0.5\n",
        "        transforms.CenterCrop(size=224),  # Crop the center of the image to 224x224 pixels\n",
        "        transforms.ToTensor(),  # Convert image to PyTorch tensor format\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],  # Normalize image using mean\n",
        "                             [0.229, 0.224, 0.225])  # Normalize image using std deviation\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(size=256),  # Resize the image to 256 pixels on the shorter side\n",
        "        transforms.CenterCrop(size=224),  # Crop the center of the image to 224x224 pixels\n",
        "        transforms.ToTensor(),  # Convert image to PyTorch tensor format\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],  # Normalize image using mean\n",
        "                             [0.229, 0.224, 0.225])  # Normalize image using std deviation\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),  # Resize the image to 256 pixels on the shorter side\n",
        "        transforms.CenterCrop(size=224),  # Crop the center of the image to 224x224 pixels\n",
        "        transforms.ToTensor(),  # Convert image to PyTorch tensor format\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],  # Normalize image using mean\n",
        "                             [0.229, 0.224, 0.225])  # Normalize image using std deviation\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoHa28JYEjhd"
      },
      "source": [
        "### 3.2. Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqB1PotzOLTF",
        "outputId": "f38b057f-dcab-4b20-b7a1-a64887962b89"
      },
      "outputs": [],
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "dataset = 'caltech256_subset'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train')\n",
        "valid_directory = os.path.join(dataset, 'valid')\n",
        "test_directory = os.path.join(dataset, 'test')\n",
        "\n",
        "# Batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(valid_directory))  #10#2#257\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "print(idx_to_class)\n",
        "\n",
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_data_loader = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
        "valid_data_loader = DataLoader(data['valid'], batch_size=batch_size, shuffle=False)\n",
        "test_data_loader = DataLoader(data['test'], batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mUcSMIMOLTG",
        "outputId": "84a38f22-09fe-4f32-93fa-adb039164dd9"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Number of training samples:   {train_data_size}\")\n",
        "print(f\"Number of validation samples: {valid_data_size}\"),\n",
        "print(f\"Number of test samples:       {test_data_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSXgbdjrEohL"
      },
      "source": [
        "## 4. Load the **ResNet50** Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViY8viSLOLTH"
      },
      "outputs": [],
      "source": [
        "# Load pretrained ResNet50 Model\n",
        "resnet50 = models.resnet50(weights='DEFAULT')\n",
        "resnet50 = resnet50.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU6Nnzk_E7tX"
      },
      "source": [
        "### 4.1. Set all the layers to be freezed initially\n",
        "\n",
        "\n",
        "By setting the `param.requires_grad = False` we ensure that all the model weights for those layers are freezed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Zma3RjZpWB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eVi7mJZOLTH"
      },
      "outputs": [],
      "source": [
        "# Freeze model parameters\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YvtqjiEFFO-"
      },
      "source": [
        "### 4.2. Unfreeze the final layer of the classifier's head\n",
        "\n",
        "As our dataset contains just 10 classes we have to modify the model's final layer from IMAGENET 1000 classes to match the num of classes of the subset dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqMKMqdWOLTH"
      },
      "outputs": [],
      "source": [
        "# Change the final fully connected layer of the ResNet50 model for transfer learning\n",
        "fc_inputs = resnet50.fc.in_features  # Get the number of input features for the final layer\n",
        "\n",
        "# Define a new fully connected layer with custom architecture for classification\n",
        "resnet50.fc = nn.Sequential(\n",
        "    nn.Linear(fc_inputs, 256),  # Fully connected layer with 256 neurons\n",
        "    nn.ReLU(),  # Apply ReLU activation\n",
        "    nn.Dropout(0.4),  # Apply dropout with 40% probability to prevent overfitting\n",
        "    nn.Linear(256, num_classes),  # Output layer with number of classes as output neurons\n",
        "    nn.LogSoftmax(dim=1)  # Apply LogSoftmax for multi-class classification (used with NLLLoss)\n",
        ")\n",
        "\n",
        "# Move the model to the appropriate device (either CUDA or CPU)\n",
        "resnet50 = resnet50.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAHhNDYxGKxQ"
      },
      "source": [
        "### 4.3. Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lske-iPOLTI"
      },
      "outputs": [],
      "source": [
        "# Define the loss function for classification\n",
        "loss_func = nn.NLLLoss()  # NLLLoss is suitable for multi-class classification\n",
        "\n",
        "# Define the learning rate for the optimizer\n",
        "learning_rate = 0.01  # Initial learning rate for the optimizer\n",
        "\n",
        "# Define the optimizer using Stochastic Gradient Descent (SGD)\n",
        "optimizer = optim.SGD(\n",
        "    params=resnet50.parameters(),  # Optimizing all parameters of the ResNet50 model\n",
        "    lr=learning_rate,  # Learning rate value\n",
        "    momentum=0.9  # Momentum term to improve convergence and avoid local minima\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, param in resnet50.named_parameters():\n",
        "    # if 'fc' in name:\n",
        "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtgYyNSVGPL5"
      },
      "source": [
        "## 5. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyG4bCHHOLTI"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    \"\"\"\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "\n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_loss = 100000.0\n",
        "    best_epoch = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "\n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "\n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "            #print(\"Batch number: {:03d}, Training Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "\n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            best_epoch = epoch\n",
        "            # Save if the model has best accuracy till now\n",
        "            torch.save(model, 'best_model.pt')\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size\n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_valid_loss = valid_loss/valid_data_size\n",
        "        avg_valid_acc = valid_acc/valid_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
        "\n",
        "        epoch_end = time.time()\n",
        "\n",
        "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return model, history, best_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIVZTrxAOLTN",
        "outputId": "0d7ecb2c-b7b2-4de0-fafc-11c5318addbe"
      },
      "outputs": [],
      "source": [
        "# Print the model to be trained.\n",
        "print(summary(resnet50, input_size=(batch_size, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxV33iRbo18y",
        "outputId": "40d7850d-a655-4ce3-ad0d-557b9448f258"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "num_epochs = 25\n",
        "trained_model, history, best_epoch = train_and_validate(resnet50, loss_func, optimizer, num_epochs)\n",
        "\n",
        "torch.save(history, dataset+'_history.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMJzkQvTGT3Q"
      },
      "source": [
        "### 5.1. Plotting the Training Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "pGcRnfbiOLTS",
        "outputId": "17d7d9e2-d354-47aa-9b9d-eda228d30000"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('loss_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "1e8oWgPWOLTS",
        "outputId": "645e9709-ef7d-489f-9539-a3d68d8cb44d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('accuracy_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2jctYiuXClo"
      },
      "source": [
        "Let's define a custom evaluation function that calculates the accuracy metric of our trained model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGHpMyvHOLTS"
      },
      "outputs": [],
      "source": [
        "def computeTestSetAccuracy(model, loss_criterion):\n",
        "    \"\"\"\n",
        "    Computes the accuracy and loss of the model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): The trained model to evaluate.\n",
        "    loss_criterion (torch.nn.Module): The loss function used for evaluation.\n",
        "\n",
        "    The function runs inference on the test dataset without tracking gradients,\n",
        "    calculates the loss and accuracy for each batch, and returns the average loss and accuracy.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    test_acc = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    # Validation - No gradient tracking needed\n",
        "    with torch.no_grad():\n",
        "        # Set to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Validation loop\n",
        "        for j, (inputs, labels) in enumerate(test_data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "\n",
        "            # Compute the total loss for the batch and add it to test_loss\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Calculate test accuracy\n",
        "            _, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "            # Compute total accuracy in the whole batch and add to test_acc\n",
        "            test_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "            print(f\"Test Batch number: {j:03d}, Test: Loss: {loss.item():.4f}, Accuracy: {acc.item():.4f}\")\n",
        "\n",
        "    # Find average test loss and test accuracy\n",
        "    avg_test_loss = test_loss / test_data_size\n",
        "    avg_test_acc = test_acc / test_data_size\n",
        "\n",
        "    print(\"Test accuracy: {:.4f}\".format(avg_test_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xS1JouOW_Ti"
      },
      "source": [
        "Just by training for additional 20 epochs, we got a tremendous improvement in model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RKePsA9He4D",
        "outputId": "15cd33cb-3b67-4e9e-9974-bf4faa3fef1c"
      },
      "outputs": [],
      "source": [
        "# Load the best saved model during training.\n",
        "model = torch.load(\"best_model.pt\".format(dataset, best_epoch), weights_only=False)\n",
        "# Evaluate the model's performance on the test dataset and print the results.\n",
        "computeTestSetAccuracy(model, loss_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d3MBRsTGyAK"
      },
      "source": [
        "## 6. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBHeFS7QOLTT"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_image_name):\n",
        "    \"\"\"\n",
        "    Predicts the class of a given test image using a trained model.\n",
        "\n",
        "    Parameters:\n",
        "    model (torch.nn.Module): The trained model to use for prediction.\n",
        "    test_image_name (str): The file path of the test image.\n",
        "\n",
        "    The function loads the image, applies necessary transformations, and\n",
        "    passes it through the model to get the top 3 predictions with their confidence scores.\n",
        "    \"\"\"\n",
        "    # Applies the predefined transformation pipeline for test images\n",
        "    transform = image_transforms['test']\n",
        "\n",
        "    test_image = Image.open(test_image_name)\n",
        "\n",
        "    # Creates a figure to visualize the test image\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(test_image)  # Displays the test image before applying transformations\n",
        "    plt.axis('off')  # Removes the axis for a cleaner image visualization\n",
        "\n",
        "    # Apply transformations and reshape to fit model input\n",
        "    test_image_tensor = transform(test_image)\n",
        "    test_image_tensor = test_image_tensor.view(1, 3, 224, 224)  # Reshape for batch processing\n",
        "\n",
        "    # Checks if a GPU is available and moves the tensor to CUDA if possible\n",
        "    if torch.cuda.is_available():\n",
        "        test_image_tensor = test_image_tensor.cuda()\n",
        "\n",
        "    with torch.no_grad():  # Disables gradient computation to optimize inference performance\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        out = model(test_image_tensor)  # Get model predictions\n",
        "        ps = torch.exp(out)  # Convert log probabilities to actual probabilities\n",
        "\n",
        "        # Extract the top 3 predictions and their probabilities\n",
        "        topk, topclass = ps.topk(3, dim=1)\n",
        "        cls = idx_to_class[topclass.cpu().numpy()[0][0]]  # Get the top predicted class\n",
        "        score = topk.cpu().numpy()[0][0]  # Get the top prediction confidence score\n",
        "\n",
        "        # Print the top 3 predictions with their confidence scores\n",
        "        for i in range(3):\n",
        "            print(f\"Prediction {i+1}: {idx_to_class[topclass.cpu().numpy()[0][i]]}\",\n",
        "                  f\"Score: {topk.cpu().numpy()[0][i]*100:.3f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXg8_TtCGnF9"
      },
      "outputs": [],
      "source": [
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2022/10/skunk.jpg\" -O \"skunk.jpg\"\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/02/Zebra.jpg\" -O \"Zebra.jpg\"\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/llama-scaled.jpg\" -O \"llama.jpg\"\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/llama_-scaled.jpg\" -O \"llama_.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4XJ---KXk-n"
      },
      "source": [
        "Let's perform some predictions which shows the top 3 prediction probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "vK8eHndnOLTU",
        "outputId": "b18cdd12-4938-472e-9170-44d35bebfd86"
      },
      "outputs": [],
      "source": [
        "predict(model, 'skunk.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "ERXiQ_7mIfBE",
        "outputId": "374742e0-2313-42aa-92ba-4f4fce5a5d72"
      },
      "outputs": [],
      "source": [
        "predict(model, 'Zebra.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "7TRgVXWfKCkg",
        "outputId": "dc813b1a-a654-4ac6-caa5-c49691f2527e"
      },
      "outputs": [],
      "source": [
        "predict(model, 'llama.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "Ad8J4bHJKx-9",
        "outputId": "ae24fb6a-3576-4769-dac9-1131c3a7732a"
      },
      "outputs": [],
      "source": [
        "predict(model, 'llama_.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpWiLmpZG4D_"
      },
      "source": [
        "## 7. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpYXF9KjPtUG"
      },
      "source": [
        "In this notebook, we have seen how we can leverage pre-trained models originally trained on the **ImageNet** data to obtain amazing levels of accuarcy without significant effort with transfer learning.\n",
        "\n",
        "This is possible because of the fact that all the 10 classes, are already contained in the ImageNet dataset.\n",
        "\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "To train classes that are not in imagenet, we can finetune our model with pretrained weights to adapt to the new dataset. You are encouraged to\n",
        "self explore on how to finetune a torchvision model on custom dataset.\n",
        "\n",
        "Fine-tuning pre-trained models is a powerful technique that allows you to re-purpose a model for a custom dataset. Torchvision comes bundled with many pre-trained classification models, allowing you to conveniently load a model in memory and configure it for Fine-Tuning. Let's summarize the key steps required for fine-tuning a pre-trained model.\n",
        "\n",
        "When fine-tuning pre-trained models, we only load the convolutional base of the model, which is initialized with ImageNet weights.  We \"freeze\" the first few layers of the convolutional base but allow the last few layers to be trained (\"fine-tuned\"). These steps are accomplished with the `param.requires_grad` to toggle which layers are trainable and which are not. The number of layers to fine-tune is something you need to experiment with. The classifier needs to be redefined based on the dataset and is initialized with random weights. In this way, the model's initial state is in a favorable position for continued learning that allows it to adapt to a new dataset and learn faster (and potentially better) than training a model from scratch. This approach also allows the model to be re-purposed for a new dataset with much less data than would be required for training a model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdYpUEu-ZqpX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "opencv-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
